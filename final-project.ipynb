{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11eaa8c-b571-4b35-9f47-2d46942b4b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Projet  **<span style=\"color: #CC146C\">Quiz generator </span>** üí° - Python pour le data-scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97dc5b5-07c5-475d-ac20-3fb9152a49f5",
   "metadata": {},
   "source": [
    "#### Auteurs : Adrien Servi√®re, M√©lissa Tamine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30fb31-5f64-4c4e-9443-bde900eeaa17",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est de pr√©senter le projet que nous avons effectu√© dans le cadre de l'unit√© d'enseignement **Python pour le data-scientist** dispens√©e √† l'ENSAE. Ce projet a √©t√© √©labor√© de mani√®re libre et comporte, comme attendu, un **jeu de donn√©es** r√©cup√©r√© et trait√©, une partie **visualisation** et une partie **mod√©lisation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b62f9-c142-4036-b5c4-fb3915b9b903",
   "metadata": {},
   "source": [
    "# Probl√©matique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a66d9-30b4-4331-af01-c8b7e7593e91",
   "metadata": {},
   "source": [
    "Notre projet s'articule autour de la probl√©matique suivante : **Comment cr√©er un syst√®me capable de g√©n√©rer un quiz (plusieurs paires de question/r√©ponse) sur un th√®me pr√©cis ?**\n",
    "\n",
    "Dans la mesure o√π l'objectif principal d'un quiz est d‚Äô√©valuer les connaissances d‚Äôun participant, il nous a sembl√© qu'un tel syst√®me pourrait s'av√©rer tr√®s utile √† des enseignants afin de tester de mani√®re ludique les acquis de leurs √©l√®ves par exemple. \n",
    "\n",
    "C'est pourquoi nous avons mod√©lis√© la structure suivante afin que le syst√®me cr√©√© puisse r√©pondre au probl√®me :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f75d2-50c1-406d-a09a-a6eafa6b5045",
   "metadata": {},
   "source": [
    "![framework](./data/images/framework.png \"Structure du syst√®me impl√©ment√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7bcd72-8045-4205-a2df-6b2f4fdd9f43",
   "metadata": {},
   "source": [
    "La structure est divis√©e en deux parties distinctes : \n",
    "1. Une partie **traitement des donn√©es** qui a principalement consist√© √† extraire et indexer dans ElasticSearch la base de donn√©es Wikip√©dia sur laquelle le mod√®le se fonde.\n",
    "2. Une partie **mod√©lisation** fond√©e sur la mise en place d'une *pipeline* form√©e de plusieurs outils de traitement du langage et mod√®les de langages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a09790-dd34-480d-9530-f9e36639224d",
   "metadata": {},
   "source": [
    "# Installations et recommandations pr√©alables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e7972-a683-4136-b641-3a6428d2667b",
   "metadata": {},
   "source": [
    "Avant d'ex√©cuter veuillez proc√©der aux installations de modules n√©cessaires au bon fonctionnement du code en ex√©cutant la cellule ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46a65bfd-541b-40cd-a353-29a53fc5b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch\n",
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!python3 -m spacy download en\n",
    "!pip install pywaffle\n",
    "!pip install stanza\n",
    "!pip install pytorch_lightning\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install strsimpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e15cfb-021b-42a0-a0ac-dfac1098511d",
   "metadata": {},
   "source": [
    "De m√™me, nous vous demanderons d'ex√©cuter les cellules de ce notebook au sein d'un **espace de travail muni d'un service ElasticSearch pr√©alablement ex√©cut√©** afin que la partie indexation puisse fonctionner. Nous vous conseillons d'utiliser **SSP Cloud** car la technologie ElasticSearch y est disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966f658-3b46-41e5-aa46-e3f673283c1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importation des modules utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73a3a14-01af-4268-a62d-b233b4199d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from src.scripts.wikipedia_indexing import *\n",
    "from src.data.constants import *\n",
    "from src.data.visualisation import *\n",
    "import stanza\n",
    "from src.scripts.quiz_generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07411616-6de1-44b4-934a-521c4e01accf",
   "metadata": {},
   "source": [
    "# R√©cup√©ration et traitement des donn√©es üóÇÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae3a12-5116-4899-916a-3bf8473273d6",
   "metadata": {},
   "source": [
    "## Extraction des donn√©es textuelles provenant de l'encyclop√©die Wikip√©dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa3865-0ab0-47e8-8d84-3653e7717b7f",
   "metadata": {},
   "source": [
    "La premi√®re √©tape de notre projet a √©t√© la **r√©cup√©ration** et le **traitement des donn√©es**. Dans notre cas, nous avons fait le choix de r√©cup√©rer des donn√©es textuelles provenant d'articles de l'encyclop√©die en ligne **Wikip√©dia**. \n",
    "\n",
    "Pour des raisons de volume, nous avons extrait les donn√©es brutes de la version en anglais simple de Wikip√©dia (en anglais : *Simple English Wikipedia*) plut√¥t que les versions en anglais ou en fran√ßais bien trop volumineuses. Il s'agit d'une encyclop√©die sp√©cialement fond√©e pour ¬´ des √©tudiants, des enfants ou des adultes ayant des difficult√©s de compr√©hension et pour ceux qui souhaiteraient apprendre l'anglais ¬ª. En novembre 2021, date √† laquelle nous avons extrait les donn√©es brutes, le site contenait plus de **200 000 pages** diff√©rentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0787d1-1d6e-4074-8795-70784c5e52e9",
   "metadata": {},
   "source": [
    "Afin d'extraire ces donn√©es brutes et de les convertir en donn√©es textuelles pouvant √™tre exploit√©es, nous avons utilis√© l'outil ```Wikiextractor``` (https://attardi.github.io/wikiextractor/) de la mani√®re suivante dans un terminal :\n",
    "```\n",
    ">>> wget \"http://download.wikimedia.org/simplewiki/latest/simplewiki-latest-pages-articles.xml.bz2\"\n",
    "\n",
    ">>> python -m wikiextractor.WikiExtractor -o \"./quiz-generator/data/wikipedia/\" --json --processes 12 \"quiz-generator/data/wikipedia/simplewiki-latest-pages-articles.xml.bz2\"\n",
    "\n",
    ">>> rm \"./quiz-generator/data/wikipedia/simplewiki-latest-pages-articles.xml.bz2\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaac05e-43f2-4af1-9aca-51033d2c58f0",
   "metadata": {},
   "source": [
    "Ces commandes nous ont permis d'obtenir les plus de 200 000 pages de donn√©es textuelles sous la forme de plusieurs fichiers .txt format√©s comme des donn√©es au format JSON que vous trouverez dans le dossier *data* du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666371d-bfe1-4375-9fa9-30f7e1bd8101",
   "metadata": {},
   "source": [
    "## Indexation des donn√©es textuelles dans ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12c2fe-c033-4c20-bd15-bb39905c2495",
   "metadata": {},
   "source": [
    "Une fois les donn√©es r√©cup√©r√©es, il a ensuite fallu les traiter. Le traitement a principalement consist√© √† indexer ces donn√©es textuelles dans *ElasticSearch*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f805ca-fdd8-42cb-8510-870c77482908",
   "metadata": {},
   "source": [
    "ElasticSearch c‚Äôest un logiciel qui fournit un moteur de recherche install√© sur un serveur (dans notre cas le serveur SSP Cloud) qu‚Äôil est possible de requ√™ter depuis un client (ce Notebook en l'occurence). C‚Äôest un moteur de recherche tr√®s performant, puissant et flexible sur donn√©es textuelles. L'objectif de l'utilisation d'un tel outil est de trouver, dans un corpus de grande dimension, un certain texte. **Dans notre cas, il s'agit de trouver les textes les plus pertinents sur un th√®me donn√© parmi l'ensemble des donn√©es textuelles comprises dans les 200 000 pages de donn√©es disponibles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7fc002-c7ac-4e57-a635-55d7e4e14f53",
   "metadata": {},
   "source": [
    "Nous utilisons la librairie python ```elasticsearch``` pour dialoguer avec notre moteur de recherche Elastic. La ligne de code ci-dessous permet d'√©tablir la connexion avec le cluster Elastic que vous avez d√ª lancer dans votre session SSP Cloud lors de la phase de recommandation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c5ce34-4263-447c-a147-e78229acaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = set_es_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67394850-59a7-49e6-9c7e-de89420d385a",
   "metadata": {},
   "source": [
    "Maintenant que la connexion est √©tablie, nous pouvons passer √† l'√©tape **d'indexation**. Cette √©tape consiste √† envoyer les documents parmi lesquels nous souhaitons chercher des echos pertinents dans notre elastic. Un index est donc une collection de document. Dans notre cas, les documents sont les paragraphes qui composent les articles du *Simple English Wikipedia*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4feab-4830-429d-b2ee-48d511f48926",
   "metadata": {},
   "source": [
    "**Remarque :** L'ex√©cution de la ligne suivante qui permet l'indexation est relativement longue, veuillez compter environ 7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d88ff1f8-a745-4e4b-a203-8b8527758630",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_indexing(client=es, args=fill_default_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacf137-6a19-446c-80ef-f78e8469f177",
   "metadata": {},
   "source": [
    "## Ex√©cution d'une premi√®re requ√™te test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05621f-c626-4033-b83c-c504083c2548",
   "metadata": {},
   "source": [
    "Maintenant que l'√©tape d'indexation est finalis√©e, il est d√©sormais possible de lancer notre premi√®re **requ√™te** c'est √† dire de chercher les documents les plus pertinents √† propos d'un th√®me (un certain mot). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5b8a7-98a3-4ecd-a1a1-42bf243e4119",
   "metadata": {},
   "source": [
    "Pour cela, nous utilisons l'algorithme d'extraction d'information BM25 que nous avons impl√©ment√© et qui utilise simplement la m√©thode interne de pond√©ration des mots utilis√©e par ElasticSearch. La pertinence d‚Äôun mot pour notre recherche est construite sur une variante de la **TF-IDF**, consid√©rant qu‚Äôun terme est pertinent s‚Äôil est souvent pr√©sent dans le document (Term Frequency) alors qu‚Äôil est peu fr√©quent dans les autres document (inverse document frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11abab9e-f58d-482d-b949-9e23c978cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever(client=es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9fc72-984e-4de1-89f1-a8069a045415",
   "metadata": {},
   "source": [
    "Nous d√©cidons par exemple de chercher les documents c'est √† dire les paragraphes inclus dans le *Simple English Wikipedia* les plus pertinents traitant du philosophe **Emmanuel Kant**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8896b8c-9a7a-45bd-9c98-a2aa6b23dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = bm25.retrieve(query='kant')\n",
    "text_contexts = [context.text for context in contexts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc8fb87-bba8-4726-99c9-2ae79528dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = ' \\n ------ \\n'\n",
    "print(f\"{nl}{nl.join(text_contexts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8ab03-7f94-4764-88a6-c8b50bcc24e9",
   "metadata": {},
   "source": [
    "Ces 10 paragraphes pertinents √† propos d'Emmanuel Kant pourront √™tre utilis√©s comme **\"contextes\"** dans la phase de mod√©lisation. Mais avant de nous y int√©resser, tentons de **visualiser les donn√©es** √† notre dispositions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cb0fa-fdd0-4057-89f4-940ae13163a8",
   "metadata": {},
   "source": [
    "# Visualisation des donn√©es üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ba241-cd35-453d-9be0-d018cf88cd64",
   "metadata": {},
   "source": [
    "Afin d'observer certains graphiques int√©ressants concernant nos donn√©es, nous allons utiliser pour l'exemple les paragraphes pertinents √† propos d'Emmanuel Kant extraits pr√©c√©demment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f33b7f-7939-429a-8df0-1c59fd6766d0",
   "metadata": {},
   "source": [
    "## Pr√©paration pr√©alable des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d08c3f-f478-4dfd-9a96-b7455c85ed47",
   "metadata": {},
   "source": [
    "Nous commen√ßons par charger ces paragraphes dans un objet TextProcessing et par les \"pr√©parer\" (la pr√©paration consiste √† retirer les espaces superflus en d√©but et fin de paragraphe, √† passer le texte en minuscule et √† le diviser en *tokens*) afin que la visualisation soit plus ais√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d520ecbd-35e5-4887-9346-641a0da66447",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p = TextProcessing(retrieved_contexts = contexts)\n",
    "t_p.load()\n",
    "t_p.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087d925-7f15-41b3-bf77-db9649b9e59f",
   "metadata": {},
   "source": [
    "Nous pouvons alors afficher les 10 premiers tokens ainsi obtenus par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071bd906-b1b4-41b5-8b64-a03753973df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p.text_split[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd544040-28f4-44a6-bca5-23ba7d93e10b",
   "metadata": {},
   "source": [
    "## Fr√©quences de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bafcf0-5180-42e7-a722-32cb02ca8a5e",
   "metadata": {},
   "source": [
    "Une fois les donn√©es charg√©es et pr√©par√©es, il est possible de s'int√©resser aux **fr√©quences des diff√©rents mots** (les 15 plus fr√©quents dans notre cas) dans l'ensemble des paragraphes pertinents √† propos d'Emmanuel Kant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376c9f70-91b4-4433-916a-2360f1193515",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cardinalities = cardinality_of_words(t_p.text_split)\n",
    "common_words = list(sorted_cardinalities.items())[:N_MOST_COMMON]\n",
    "common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc66ae-93fa-44fd-9ac9-77f1e55f4812",
   "metadata": {},
   "source": [
    "Nous pouvons **afficher sous forme de graphique** ces diff√©rentes fr√©quences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c45410-e20a-48d4-990b-795002d92df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w[0] for w in common_words]\n",
    "counts = [w[1] for w in common_words]\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(15, 9))\n",
    "seaborn.barplot(x = words, y = counts).set_title(\"Mots les plus fr√©quents dans l'ensemble des paragraphes extraits\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a2e52-878d-419b-bb56-67ecd36c797c",
   "metadata": {},
   "source": [
    "Nous pouvons constater que des mots tels que *the*, *of*, *and* ou encore *in* figurent parmis les termes les plus fr√©quents. En recherche d'information, de tels mots sont appel√©s **mots vides** (ou *stop words*, en anglais). Il s'agit de mots tellement communs qu'il est inutile de les utiliser dans une recherche car ils sont peu instructifs sur le contexte √©tudi√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba9500-8a39-4e3e-9ac2-b4039c6744fb",
   "metadata": {},
   "source": [
    "Nous pouvons donc afficher les fr√©quences de mots mais cette fois-ci en **supprimant les mots vides** afin de mettre en lumi√®re les mots fr√©quents les plus pertinents et significatifs des paragraphes extraits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac5fae7-2507-41d7-b1b3-389a4f205b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_stopwords = t_p.without_stopwords()\n",
    "cardinalities = Counter(text_without_stopwords)\n",
    "words = [cardinality[0] for cardinality in cardinalities.most_common(N_MOST_COMMON)]\n",
    "counts = [cardinality[1] for cardinality in cardinalities.most_common(N_MOST_COMMON)]\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(15, 9))\n",
    "seaborn.barplot(x = words, y = counts).set_title(\"Mots pleins les plus fr√©quents dans l'ensemble des paragraphes extraits\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0e641-47e5-4519-a019-590ca141e072",
   "metadata": {},
   "source": [
    "Les mots ainsi affich√©s mettent en lumi√®re la pertinence des paragraphes extraits par l'algorithme BM25 vis √† vis du th√®me choisi √† savoir Emmanuel Kant, *kant* √©tant largement le mot le plus fr√©quent. Les autres mots fr√©quents tels que *critique* et *reason* faisant echo √† son oeuvre principale ou encore *philosophy* sont √©galement repr√©sentatifs du th√®me choisi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de566eee-47d6-4d98-bcd9-f07d0f4c7196",
   "metadata": {},
   "source": [
    "Il est √©galement possible de comparer la fr√©quence d'un m√™me mot selon les diff√©rents paragraphes extraits sur un m√™me th√®me. La cellule suivante permet d'afficher le nombre d'occurence du terme *kant* dans les 10 paragraphes extraits sous la forme d'un *waffle chart*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b5307e-83e1-4a2c-a04a-ee3c62d9037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = graph_occurrence(\"kant\", contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a80ef-6722-4832-869d-12a87a94a4e9",
   "metadata": {},
   "source": [
    "## Nuage de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062daf70-b7dd-4ca8-bf1f-62f5a7fbe1ca",
   "metadata": {},
   "source": [
    "Il est √©galement possible de repr√©senter les mots des paragraphes pertinents √† propos d'Emmanuel Kant sous la forme de nuage de mots cl√©s (ou *word clouds* en anglais). Le nuage de mots cl√©s est une sorte de condens√© s√©mantique d'un texte dans lequel les concepts clefs √©voqu√©s sont dot√©s d'une unit√© de taille (dans le sens du poids de la typographie utilis√©e) permettant de faire ressortir leur importance dans le texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1bede4-6f7f-4b7f-a5c0-ac71e3912955",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500,\n",
    "                      #random_state=21, max_font_size=110).generate(t_p.text)\n",
    "plt.figure(figsize=(19, 12))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e209f-1b90-44f2-b757-faf76b6091bc",
   "metadata": {},
   "source": [
    "Cette visualisation permet d'obtenir une sorte r√©sum√© des paragraphes pertinents dont on voit directement appara√Ætre les id√©es cl√©s et donc importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cc920-9419-488c-9ac6-a129cf580dfa",
   "metadata": {},
   "source": [
    "## Word embedding (vectorisation des mots) et visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08757eb-7dc1-46b4-b2a2-70909e5fe74b",
   "metadata": {},
   "source": [
    "Le **word embedding** est une m√©thode d'apprentissage d'une repr√©sentation de mots utilis√©e en traitement automatique des langues. Cette technique permet de repr√©senter chaque mot d'un corpus de textes par un vecteur de nombres r√©els. Cette nouvelle repr√©sentation a ceci de particulier que **les mots apparaissant dans des contextes similaires poss√®dent des vecteurs correspondants qui sont relativement proches**. Par exemple, on pourrait s'attendre √† ce que les mots ¬´ chien ¬ª et ¬´ chat ¬ª soient repr√©sent√©s par des vecteurs relativement peu distants dans l'espace vectoriel o√π sont d√©finis ces vecteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a781a-4d91-4071-a2be-619b5d6703c7",
   "metadata": {},
   "source": [
    "Nous pouvons donc utiliser un mod√®le de vectorisation de mots d√©j√† entra√Æn√© puis des m√©thodes de r√©duction de dimmensions afin de visualiser dans l'espace latent des mots anglais, les mots fr√©quents des paragraphes extraits √† propos d'Emmanuel Kant.\n",
    "\n",
    "**Remarque** : Nous choisissons de ne vectoriser et repr√©senter que quelques mots seulement dans un soucis de lisibilit√© du graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66cfe460-8cbd-4ddf-97a4-845ba9c5f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embedding(MODEL_NAME)\n",
    "e.embedding(t_p.text[:301])\n",
    "words_embedding_dim_2 = e.pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f5a840-123f-4bf7-a48d-0b9a8cf7a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set()\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(words_embedding_dim_2[:,0], words_embedding_dim_2[:,1], 'b', label = 'Vecteurs de mots', linewidth=0, marker = '*')\n",
    "plt.title('Word Embedding sur les premiers mots des paragraphes extraits')\n",
    "plt.xlabel('Premi√®re dimension')\n",
    "plt.ylabel('Deuxi√®me dimension')\n",
    "plt.legend()\n",
    "for i, w in enumerate(e.words):\n",
    "    plt.annotate(w, xy=(words_embedding_dim_2[i, 0], words_embedding_dim_2[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdd5a1-3b6a-4300-b3e5-889b4f70bb63",
   "metadata": {},
   "source": [
    "Il appara√Æt par exemple que les termes *philosophers*, *kant* et *ideas* sont proches dans l'espace latent de mots ce qui est coh√©rent avec la s√©mantique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6aa21-cddc-43d5-bf41-5ba1331a6e82",
   "metadata": {},
   "source": [
    "# Mod√©lisation üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae5f5d-09f8-4336-bae5-7ba9a5380338",
   "metadata": {},
   "source": [
    "√Ä pr√©sent, nous pouvons nous int√©resser √† la v√©ritable motivation de ce projet √† savoir l'impl√©mentation d'une *pipeline* permettant de **g√©n√©rer un quiz** (paires de questions/r√©ponses) sur un th√®me donn√©. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68a879-a3ba-4298-8fa9-f386421270cb",
   "metadata": {},
   "source": [
    "Les diff√©rentes composantes de la *pipeline* permettent de r√©aliser les √©tapes suivantes :\n",
    "\n",
    "1. √Ä partir des contextes (paragraphes) pertinents sur le th√®me donn√© (ici Emmanuel Kant) extraits de notre base textuelle initiale gr√¢ce au **BM25 Retriever**, nous pouvons extraire gr√¢ce √† un outil de **Name Entity Recognition**, des noms propres, dates, lieux ou organisations susceptibles de consistuer des r√©ponses potentielles √† des questions.\n",
    "2. Un g√©n√©rateur de questions appel√© **T5** d√©j√† pr√©-entra√Æn√© et *fine-tun√©* nous permet de g√©n√©rer, en prenant en entr√©e un contexte et une r√©ponse, une question coh√©rente.\n",
    "3. La s√©rie de questions/r√©ponses ainsi obtenue est ensuite filtr√©e pour ne conserver que les paires les plus pertinentes et correctes gr√¢ce √† une m√©thode de filtrage appel√©e *Roundtrip* pens√©e et expliqu√©e dans l'article suivant : https://aclanthology.org/P19-1620.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff9daf-f0ea-4897-ba30-64578efb75f2",
   "metadata": {},
   "source": [
    "## Extraction de r√©ponses par reconnaissance d'entit√©s nomm√©es (Name Entity Recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f32b6b-b36e-47fc-aa15-efa0252dec9b",
   "metadata": {},
   "source": [
    "L'id√©e de cette premi√®re √©tape est d'extraire des r√©ponses potentielles aux futures questions g√©n√©r√©es √† partir des contextes pertinents sur le th√®me choisi (ici Kant en l'occurence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe607e-b301-466d-a068-d8bbd0061540",
   "metadata": {},
   "source": [
    "Nous utilisons pour cela l'outil de reconnaissance d'entit√©s nomm√©es de l'Universit√© de Standford appel√© ```stanza``` que nous commen√ßons par t√©l√©charger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6af866-a387-4130-8085-745edf24cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd().split('src')[0]\n",
    "sys.path.append(project_dir)\n",
    "stanza.download('en', model_dir=\"data/stanza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af8232-c0fc-4b7a-9892-78a9ee3c6068",
   "metadata": {},
   "source": [
    "Puis √† l'aide de la fonction impl√©ment√©e ```extract_answers_from_contexts()```nous pouvons extraire des r√©ponses potentielles dans les contextes pertinents sur Emmanuel Kant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9162801f-421f-4686-b07b-dbd500997501",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [Question(retrieved_contexts = [context]) for context in contexts]\n",
    "qca = QuestionContextAnswer(questions = questions)\n",
    "qca = extract_answers_from_contexts(qca, \"data/stanza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141ef3c-5498-4c98-a8df-ec4f8d596743",
   "metadata": {},
   "source": [
    "En voici quelques exemples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa98b70-bb76-4ab9-a95b-8f58d4f77c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_answers = [answer.text for answer in qca.get_all_answers()]\n",
    "all_answers[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd8c8a-af39-4af8-8d48-690bc8d1b0cc",
   "metadata": {},
   "source": [
    "## G√©n√©ration de questions √† partir des contextes et r√©ponses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1ffe1-ac3c-41b6-afee-d73bedad9d99",
   "metadata": {},
   "source": [
    "√Ä partir des contextes et r√©ponses extraites, nous pouvons g√©n√©rer √† l'aide du mod√®le de langage **T5**, des questions coh√©rentes avec ces contextes/r√©ponses. Pour ce faire nous utilisons un mod√®le pr√©-entra√Æn√© et *fine-tun√©* disponible en open source (https://huggingface.co/Narrativa/mT5-base-finetuned-tydiQA-question-generation) utilis√© dans notre fonction impl√©ment√©e ```generate_questions()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba95e968-97a1-4f6e-97e8-c4a5647144fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qca = generate_questions(qca, 15, model_path=\"Narrativa/mT5-base-finetuned-tydiQA-question-generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ecada-770f-4086-80f7-12c91d833abf",
   "metadata": {},
   "source": [
    "Nous obtenons au final 67 paires de questions r√©ponses diff√©rents √† partir des diff√©rents contextes et r√©ponses en entr√©e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05b27cdb-adee-4cdb-8860-298fcd7dac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Un exemple de paire de question/r√©ponse pertinente : \\n{qca.questions[15].text} / {qca.questions[15].predicted_answers[0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96d621-9ce1-4e9d-a548-68894a4d4286",
   "metadata": {},
   "source": [
    "Au vue de la paire de question/r√©ponse pr√©c√©dente, nous pourrions croire que l'ensemble des questions g√©n√©r√©es par le mod√®le **T5** sont aussi pertinentes. N√©anmoins, ce mod√®le de langage comme tous les autres est loin d'√™tre infaillible. Il peut g√©n√©rer des questions incoh√©rentes avec la r√©ponse extraite, en voici un exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1a14c8-84e1-4cdc-b40f-8e7fb2f4e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Un exemple de paire de question/r√©ponse incorrecte : \\n{qca.questions[1].text} / {qca.questions[1].predicted_answers[0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9832da-3c15-423a-b16e-2f2f7725928f",
   "metadata": {},
   "source": [
    "C'est pourquoi il est n√©cessaire de **filtrer les questions/r√©ponses** ainsi obtenues afin de ne conserver que les plus correctes dans le quiz final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4544ee-43a5-4f35-bc87-dbc64f8658c9",
   "metadata": {},
   "source": [
    "## Filtrage des questions/r√©ponses incorrectes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85072543-c7a3-4b4d-9baa-26590a777ae4",
   "metadata": {},
   "source": [
    "Le principe de cette √©tape de filtrage est de conserver uniquement les paires de questions/r√©ponses les plus pertinentes dans le quiz final. Pour cela, nous appliquons un algorithme de filtrage dont les √©tapes sont les suivantes :\n",
    "1. En prenant en entr√©e le contexte **C** et la question g√©n√©r√©e **Q**, un mod√®le de langage BERT fine-tun√© pour la t√¢che de Question Answering (disponible en open-source au lien suivant https://huggingface.co/csarron/roberta-base-squad-v1) va \"lire\" la r√©ponse √† la question la plus vraissemblable au sein du contexte. Nous nommons cette nouvelle r√©ponse **R'**.\n",
    "2. Si la r√©ponse **R** extraite par Name Entity Recognition et la r√©ponse **R'** lue par le mod√®le BERT sont suffisamment proches (au sens de la distance Leveinshtein) alors nous consid√©rons que la paire de question/r√©ponse **Q/R** est pertinente. En effet, cela signifie vraissemblablement que la question **Q** est suffisamment coh√©rente pour que le mod√®le BERT ait pu lire une r√©ponse similaire √† celle initialement associ√©e √† cette question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09595da1-90e3-44de-bb20-ffb86fc4b0cf",
   "metadata": {},
   "source": [
    "La cellule suivante permet d'appliquer ce filtre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a235570-5526-4e56-972c-d5acecf4b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qca = roundtrip_filter(qca, model_path=\"csarron/roberta-base-squad-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4df3551e-1523-4b5c-a718-0809253a83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nouvelle paire de question r√©ponse au rang 1 :\\n{qca.questions[1].text} / {qca.questions[1].predicted_answers[0].text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d262b50-a253-4ae9-95f2-19614642bec5",
   "metadata": {},
   "source": [
    "Nous constatons que la paire de question/r√©ponse incorrecte du rang 1 que nous avions pr√©cedemment affich√©e : \n",
    "> What was Kant's first philosophy? / Kant\n",
    "\n",
    "a √©t√© remplac√©e par la paire suivante :\n",
    "> Who is the most powerful philosopher? / Kant\n",
    "\n",
    "Cela signifie que la premi√®re paire de question r√©ponse a √©t√© filtr√©e ce qui laisse penser que le filtre est relativement performant pour √©liminer les questions s√©mantiquement incorrectes vis √† vis de leurs r√©ponses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f890a-4702-4ce9-896f-fb8dabc50bc5",
   "metadata": {},
   "source": [
    "# G√©n√©ration d'un quiz üí°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad82e2-fa76-48b4-a2fd-2a7b1a15befd",
   "metadata": {},
   "source": [
    "Nous vous avons ainsi pr√©sent√© les diff√©rentes √©tapes, algorithmes et mod√®les de langage utilis√© dans ce projet. Nous pouvons √† pr√©sent vous pr√©senter **l'outil de g√©n√©ration de quiz** que nous avons √©labor√© et qui reprend l'ensemble des √©tapes que nous avons √©nonc√© pr√©c√©demment. Il permet de cr√©er **un quiz de 10 questions/r√©ponses** sur un th√®me choisi (ou moins si les circonstances ont fait que l'outil n'a pas pu g√©n√©rer 10 questions r√©ponses (pauvret√© des contextes, filtrage etc.) \n",
    "\n",
    "N'h√©sitez pas √† changer le th√®me du quiz pour comparer les performances de notre outil et cr√©er les quiz de votre choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42ba9b0c-7c3d-4a9c-841f-c2de5636ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generator(theme=\"kant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6b614-4e8c-4b82-a5cb-6510bfdf82d7",
   "metadata": {},
   "source": [
    "# Pistes d'am√©lioration du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62793f56-ce00-418b-9807-c357b2e329ff",
   "metadata": {},
   "source": [
    "1. Notre objectif initial √©tait de g√©n√©rer des paires de questions r√©ponses en fran√ßais. Pour cela nous aurions d√ª fonder notre mod√®le sur la version fran√ßaise de encyclop√©die Wikip√©dia. Cependant, celle-ci √©tant trop volumineuse, elle n'√©tait pas transferable sur le serveur GitHub ce qui rendait notre travail difficilement reproductible. C'est pourquoi nous nous sommes tourn√©s vers la version *Simple English* moins riche linguistiquement mais suffisante pour utiliser les outils que nous avions impl√©ment√©s. \n",
    "\n",
    "2. Nous souhaitions √©galement *fine-tuner* nous-m√™me les mod√®les de langages **T5** et **BERT** afin d'avoir une meilleure id√©e des performances finales de ces outils. Dans notre cas, nous avons utilis√© ces mod√®les d√©j√† *fine-tun√©* par d'autres d√©veloppeurs et disponibles en open-source. L'avantage a √©t√© un gain de temps consid√©rable car l'entra√Ænement d'un mod√®le de langage peut s'av√©rer tr√®s long mais en contre partie nous ne savons pas exactement comment ces mod√®les ont √©t√© entra√Æn√©s et quelles sont leurs performances sur un dataset test : nous pouvons seulement √©valuer leur robustesse √† travers notre outil."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
